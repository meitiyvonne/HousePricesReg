import pandas as pd
import joblib
from pathlib import Path
import typing as t

from regression_model import __version__ as _version
from regression_model.config import config

# --- è¨­å®šæª”æ¡ˆè·¯å¾‘ (å¾ž config.py å–å¾—) ---
PACKAGE_ROOT = config.PACKAGE_ROOT
TRAINED_MODEL_DIR = config.TRAINED_MODEL_DIR
DATASET_DIR = config.DATASET_DIR


def load_dataset(*, file_name: str) -> pd.DataFrame:
    """è¼‰å…¥æ•¸æ“šé›†."""
    # é€™è£¡æˆ‘å€‘å‡è¨­æ•¸æ“šæ”¾åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„çš„ 'datasets' è³‡æ–™å¤¾
    # å› ç‚º config.py çš„è¨­ç½®å¯èƒ½æœ‰é»žæ­§ç¾©ï¼Œæˆ‘å€‘ç›´æŽ¥ä½¿ç”¨ä¸€å€‹è¼ƒå®‰å…¨çš„è·¯å¾‘
    
    # ä¿®æ­£ï¼šæ ¹æ“š config.py çš„é‚è¼¯ï¼Œå¦‚æžœ DATASET_DIR = PACKAGE_ROOT / "datasets"ï¼Œ
    # ä¸” PACKAGE_ROOT æ˜¯å…§å±¤æ¨¡çµ„ï¼Œå‰‡æ•¸æ“šç›®éŒ„åœ¨:
    # .../regression_model/regression_model/datasets
    
    # ç‚ºäº†ç°¡åŒ–ï¼Œæˆ‘å€‘å°‡ä½¿ç”¨çµ•å°è·¯å¾‘ä¾†è®€å–ä½æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ (HousePricesReg/) çš„ datasets/
    # ðŸ’¡ æœ€ä½³å¯¦è¸ï¼šå°‡ 'datasets' ç›®éŒ„æ”¾åœ¨ HousePricesReg/ æ ¹ç›®éŒ„
    # é€™è£¡æˆ‘å€‘å°‡è·¯å¾‘èª¿æ•´ç‚ºè®€å–å°ˆæ¡ˆæ ¹ç›®éŒ„ä¸‹çš„ 'datasets/'
    
    # é€™æ˜¯å‡è¨­æ‚¨çš„å°ˆæ¡ˆæ ¹ç›®éŒ„ (HousePricesReg) æœ‰ä¸€å€‹ datasets/ è³‡æ–™å¤¾
    # æ‚¨å¯èƒ½éœ€è¦èª¿æ•´è·¯å¾‘ï¼Œä½†å…ˆå˜—è©¦é€™å€‹ï¼š
    file_path = Path.cwd() / "datasets" / file_name
    
    if not file_path.exists():
        # å¦‚æžœæ‰¾ä¸åˆ°ï¼Œå˜—è©¦ä½¿ç”¨ config è£¡é¢çš„è·¯å¾‘
        file_path = DATASET_DIR / file_name
    
    data = pd.read_csv(file_path)
    return data


def save_pipeline(*, pipeline_to_persist) -> None:
    """å„²å­˜è¨“ç·´å¥½çš„æ¨¡åž‹ (Pipeline)."""
    
    # ç”±æ–¼ train_pipeline.py åªæ˜¯èª¿ç”¨äº† save_pipelineï¼Œé€™è£¡æä¾›å®Œæ•´å¯¦ç¾
    save_file_name = f"lasso_regression_output_v{_version}.pkl"
    save_path = TRAINED_MODEL_DIR / save_file_name

    # ç§»é™¤èˆŠçš„æ¨¡åž‹æª”æ¡ˆ (å¯é¸)
    remove_old_pipelines(files_to_keep=[save_file_name])
    
    joblib.dump(pipeline_to_persist, save_path)


def load_pipeline(*, file_name: str):
    """è¼‰å…¥å·²å„²å­˜çš„æ¨¡åž‹ (Pipeline)."""
    
    # ç”±æ–¼ predict.py ä¾è³´ 'regression_model.pkl'ï¼Œæˆ‘å€‘ç›´æŽ¥ä½¿ç”¨è©²åç¨±
    file_path = TRAINED_MODEL_DIR / file_name
    trained_pipeline = joblib.load(filename=file_path)
    return trained_pipeline


def remove_old_pipelines(*, files_to_keep: t.List[str]) -> None:
    """ç§»é™¤èˆŠçš„æ¨¡åž‹ artifact."""
    
    do_not_delete = files_to_keep + ["__init__.py"]
    for model_file in TRAINED_MODEL_DIR.iterdir():
        if model_file.name not in do_not_delete:
            model_file.unlink()